{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90131e-22a8-4c70-a01f-01fb62f3e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24889ee-1334-48a9-a4a9-82cc3df4fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd=\"--loss_type Twin_AC --AC \\\n",
    "--AC_weight 1.0 \\\n",
    "--G_shared \\\n",
    "--n_domain 4 \\\n",
    "--shuffle --batch_size 200 \\\n",
    "--num_G_accumulations 1 --num_D_accumulations 1 --num_epochs 1000 \\\n",
    "--num_D_steps 4 --num_G_steps 1 --G_lr 2e-4 --D_lr 2e-4 \\\n",
    "--source_dataset mnist,mnist_m,svhn,syn_digits --target_dataset mnist_m --num_workers 16 \\\n",
    "--G_ortho 0.0 \\\n",
    "--G_attn 0 --D_attn 0 --G_ch 64 --D_ch 64 \\\n",
    "--G_init N02 --D_init N02 \\\n",
    "--test_every 8000 --save_every 1000 --num_best_copies 5 --num_save_copies 2 --seed 2019 \\\n",
    "--ema  --use_ema --ema_start 10000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1c131-3fc7-4678-93f9-035d40096107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse command line and run\n",
    "parser = utils.prepare_parser()\n",
    "config = vars(parser.parse_args(cmd.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196b60d-3b78-4cee-8d9c-03ef228e4fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['resolution'] = 32#utils.imsize_dict[config['dataset']]\n",
    "config['n_classes'] = 10#utils.nclass_dict[config['dataset']]\n",
    "config['G_activation'] = utils.activation_dict[config['G_nl']]\n",
    "config['D_activation'] = utils.activation_dict[config['D_nl']]\n",
    "\n",
    "config['skip_init'] = True\n",
    "config = utils.update_config_roots(config)\n",
    "device = 'cuda:5'\n",
    "\n",
    "# Seed RNG\n",
    "utils.seed_rng(config['seed'])\n",
    "\n",
    "# Prepare root folders if necessary\n",
    "utils.prepare_root(config)\n",
    "\n",
    "# Setup cudnn.benchmark for free speed\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Import the model--this line allows us to dynamically select different files.\n",
    "model = __import__(config['model'])\n",
    "experiment_name = (config['experiment_name'] if config['experiment_name']\n",
    "                   else utils.name_from_config(config))\n",
    "# Next, build the model\n",
    "G = model.Generator(**config).to(device)\n",
    "D = model.Discriminator(**config).to(device)\n",
    "\n",
    "if config['ema']:\n",
    "    G_ema = model.Generator(**{**config, 'skip_init':True, 'no_optim': True}).to(device)\n",
    "    ema = utils.ema(G, G_ema, config['ema_decay'], config['ema_start'])\n",
    "else:\n",
    "    ema = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec1794-02c2-46b5-ac95-85af2d54db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "GD = model.G_D(G, D)\n",
    "state_dict = {'itr': 0, 'epoch': 929, 'save_num': 0, 'save_best_num': 0,\n",
    "                'best_IS': 0, 'best_FID': 999999, 'config': config}\n",
    "\n",
    "config['load_weights'] = '' #\"mnist,mnist_m,svhn,syn_digits_mnist_m\" #_num_domain: 4_Twin_AC_AC_weight1.0_BigGAN_seed2019_Gch64_Dch64_bs200_nDs4_Glr2.0e-04_Dlr2.0e-04_Gnlrelu_Dnlrelu_GinitN02_DinitN02_Gshared_ema_epoch929\"\n",
    "G_batch_size = max(config['G_batch_size'], config['batch_size'])\n",
    "utils.load_weights(G, D, state_dict,\n",
    "                       config['weights_root'], experiment_name, \n",
    "                       config['load_weights'] if config['load_weights'] else None,\n",
    "                       G_ema if config['ema'] else None)\n",
    "z_, y_, yd_ = utils.prepare_z_y(G_batch_size, G.dim_z, config['n_classes'],config['n_domain'],\n",
    "                             device=device, fp16=config['G_fp16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d7c4e-8e97-4f3f-a4bf-52ff20eee661",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_.sample_()\n",
    "#y_.sample_()\n",
    "#yd_.sample_()\n",
    "y = torch.tensor([i  for k in range(4) for i in range(10)]).to(device)\n",
    "yd = torch.tensor([int(k) for  k in range(4) for j in range(10) ]).to(device)\n",
    "\n",
    "#out = G(z_, G.shared(y_), G.shared_d(yd_))\n",
    "out = G(z_[:40], G.shared(y), G.shared_d(yd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25653128-e051-4e1d-8ee3-c3fef8bde7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(13, 10))\n",
    "for j in range(4):\n",
    "    for i in range(10):\n",
    "        plt.subplot(8,10,  j*10 + i+1)\n",
    "        jj = j\n",
    "        if(j == 1):\n",
    "            jj = 3\n",
    "        if(j == 3):\n",
    "            jj = 1\n",
    "        img = out[jj*10 + i] #.cpu().detach().numpy()\n",
    "        #img = (img*-1)+1\n",
    "        #plt.title((y[j*10 + i].detach().cpu().item(), yd[j*10 + i].detach().cpu().item()))\n",
    "        img = (img - img.min())/(img.max() - img.min())\n",
    "        img = img.detach().cpu().numpy().transpose(1, 2, 0)\n",
    "        if(jj == 0):\n",
    "            img = 1-img\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.savefig(\"G_syn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d3c87-b82f-4132-adb6-fbbf2b4d623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(\"real.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ecf139-9d7d-4f4a-a415-cef8740b74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.G.shared(gy),self.G.shared_d(gyd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7f5a1-4284-4a4e-b54b-b722b2d1dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  # If loading from a pre-trained model, load weights\n",
    "  if config['resume']:\n",
    "    print('Loading weights...')\n",
    "    utils.load_weights(G, D, state_dict,\n",
    "                       config['weights_root'], experiment_name, \n",
    "                       config['load_weights'] if config['load_weights'] else None,\n",
    "                       G_ema if config['ema'] else None)\n",
    "\n",
    "  # If parallel, parallelize the GD module\n",
    "  if config['parallel']:\n",
    "    GD = nn.DataParallel(GD)\n",
    "\n",
    "    if config['cross_replica']:\n",
    "      patch_replication_callback(GD)\n",
    "\n",
    "  # Prepare loggers for stats; metrics holds test metrics,\n",
    "  # lmetrics holds any desired training metrics.\n",
    "  test_metrics_fname = '%s/%s_log.jsonl' % (config['logs_root'],\n",
    "                                            experiment_name)\n",
    "  print(test_metrics_fname)\n",
    "  train_metrics_fname = '%s/%s' % (config['logs_root'], experiment_name)\n",
    "  print('Inception Metrics will be saved to {}'.format(test_metrics_fname))\n",
    "  test_log = utils.MetricsLogger(test_metrics_fname, \n",
    "                                 reinitialize=(not config['resume']))\n",
    "  print('Training Metrics will be saved to {}'.format(train_metrics_fname))\n",
    "  train_log = utils.MyLogger(train_metrics_fname, \n",
    "                             reinitialize=(not config['resume']),\n",
    "                             logstyle=config['logstyle'])\n",
    "  # Write metadata\n",
    "  utils.write_metadata(config['logs_root'], experiment_name, config, state_dict)\n",
    "  # Prepare data; the Discriminator's batch size is all that needs to be passed\n",
    "  # to the dataloader, as G doesn't require dataloading.\n",
    "  # Note that at every loader iteration we pass in enough data to complete\n",
    "  # a full D iteration (regardless of number of D steps and accumulations)\n",
    "  D_batch_size = (config['batch_size'] * config['num_D_steps']\n",
    "                  * config['num_D_accumulations'])\n",
    "\n",
    "  transforms_train = transforms.Compose([transforms.Resize(config['resolution']),transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "  print(config['base_root'])\n",
    "  data_set = source_domain_numpy(root=config['base_root'], root_list=config['source_dataset'], transform=transforms_train)\n",
    "  # loaders = utils.get_data_loaders(**{**config, 'batch_size': D_batch_size,\n",
    "  #                                     'start_itr': state_dict['itr']})\n",
    "  loaders = torch.utils.data.DataLoader(data_set, batch_size=D_batch_size, shuffle=True,\n",
    "           num_workers=config['num_workers'],\n",
    "           pin_memory=True,\n",
    "           worker_init_fn=np.random.seed,drop_last=True)\n",
    "\n",
    "  test_set_s = domain_test_numpy(root= config['base_root'],\n",
    "                               root_t=config['target_dataset'], transform=transforms_train)\n",
    "  test_loader_s = torch.utils.data.DataLoader(test_set_s, batch_size=D_batch_size, shuffle=False,\n",
    "                                            num_workers=config['num_workers'],\n",
    "                                            pin_memory=True,\n",
    "                                            worker_init_fn=np.random.seed, drop_last=True)\n",
    "\n",
    "  test_set_t = domain_test_numpy(root= config['base_root'],root_t=config['target_dataset'],transform=transforms_train)\n",
    "  test_loader_t = torch.utils.data.DataLoader(test_set_t, batch_size=D_batch_size, shuffle=False,\n",
    "           num_workers=config['num_workers'],\n",
    "           pin_memory=True,\n",
    "           worker_init_fn=np.random.seed,drop_last=True)\n",
    "\n",
    "  # Prepare noise and randomly sampled label arrays\n",
    "  # Allow for different batch sizes in G\n",
    "  G_batch_size = max(config['G_batch_size'], config['batch_size'])\n",
    "  z_, y_, yd_ = utils.prepare_z_y(G_batch_size, G.dim_z, config['n_classes'],config['n_domain'],\n",
    "                             device=device, fp16=config['G_fp16'])\n",
    "  # Prepare a fixed z & y to see individual sample evolution throghout training\n",
    "  fixed_z, fixed_y, fixed_yd = utils.prepare_z_y(G_batch_size, G.dim_z,\n",
    "                                       config['n_classes'],config['n_domain'], device=device,\n",
    "                                       fp16=config['G_fp16'])\n",
    "  fixed_z.sample_()\n",
    "  fixed_y.sample_()\n",
    "  fixed_yd.sample_()\n",
    "  # Loaders are loaded, prepare the training function\n",
    "  if config['which_train_fn'] == 'GAN':\n",
    "    train = train_fns.GAN_training_function(G, D, GD, z_, y_,yd_,\n",
    "                                            ema, state_dict, config)\n",
    "  # Else, assume debugging and use the dummy train fn\n",
    "  else:\n",
    "    train = train_fns.dummy_training_function()\n",
    "  # Prepare Sample function for use with inception metrics\n",
    "  # sample = functools.partial(utils.sample,\n",
    "  #                             G=(G_ema if config['ema'] and config['use_ema']\n",
    "  #                                else G),\n",
    "  #                             z_=z_, y_=y_, config=config)\n",
    "\n",
    "  print('Beginning training at epoch %d...' % state_dict['epoch'])\n",
    "  # Train for specified number of epochs, although we mostly track G iterations.\n",
    "  for epoch in range(state_dict['epoch'], config['num_epochs']):\n",
    "    if epoch%10 == 0:\n",
    "        test_acc(D, test_loader_s, epoch, \"s\")\n",
    "        test_acc(D, test_loader_t, epoch, \"t\")\n",
    "    # Which progressbar to use? TQDM or my own?\n",
    "    if config['pbar'] == 'mine':\n",
    "      pbar = utils.progress(loaders,displaytype='s1k' if config['use_multiepoch_sampler'] else 'eta')\n",
    "    else:\n",
    "      pbar = tqdm(loaders)\n",
    "    for i, (x_s, y, yd) in enumerate(pbar):\n",
    "      # Increment the iteration counter\n",
    "      state_dict['itr'] += 1\n",
    "      # Make sure G and D are in training mode, just in case they got set to eval\n",
    "      # For D, which typically doesn't have BN, this shouldn't matter much.\n",
    "      G.train()\n",
    "      D.train()\n",
    "      if config['ema']:\n",
    "        G_ema.train()\n",
    "      if config['D_fp16']:\n",
    "        x_s,x_t, y = x_s.to(device).half(), x_t.to(device).half(), y.to(device)\n",
    "      else:\n",
    "        x_s, y, yd = x_s.to(device), y.to(device),yd.to(device)\n",
    "      metrics = train(x_s, y, yd)\n",
    "      # train_log.log(itr=int(state_dict['itr']), **metrics)\n",
    "      \n",
    "      # Every sv_log_interval, log singular values\n",
    "      if (config['sv_log_interval'] > 0) and (not (state_dict['itr'] % config['sv_log_interval'])):\n",
    "        train_log.log(itr=int(state_dict['itr']), \n",
    "                      **{**utils.get_SVs(G, 'G'), **utils.get_SVs(D, 'D')})\n",
    "\n",
    "      # If using my progbar, print metrics.\n",
    "      if config['pbar'] == 'mine':\n",
    "          print(', '.join(['itr: %d' % state_dict['itr']] \n",
    "                           + ['%s : %+4.3f' % (key, metrics[key])\n",
    "                           for key in metrics]), end=' ')\n",
    "          wandb_metric = {key: metrics[key] if type(metrics[key]) == float else metrics[key].item() for key in metrics.keys()}\n",
    "          wandb.log(wandb_metric)\n",
    "\n",
    "      # Save weights and copies as configured at specified interval\n",
    "      if not (state_dict['itr'] % config['save_every']):\n",
    "        if config['G_eval_mode']:\n",
    "          print('Switchin G to eval mode...')\n",
    "          G.eval()\n",
    "          if config['ema']:\n",
    "            G_ema.eval()\n",
    "        train_fns.save_and_sample(G, D, G_ema, z_, y_,yd_, fixed_z, fixed_y,fixed_yd,\n",
    "                                  state_dict, config, f\"{experiment_name}_epoch{epoch}\")\n",
    "\n",
    "      # Test every specified interval\n",
    "      if not (state_dict['itr'] % config['test_every']):\n",
    "        if config['G_eval_mode']:\n",
    "          print('Switchin G to eval mode...')\n",
    "          G.eval()\n",
    "        # train_fns.test(G, D, G_ema, z_, y_, state_dict, config, sample,\n",
    "        #                get_inception_metrics, experiment_name, test_log)\n",
    "    # Increment epoch counter at end of epoch\n",
    "    state_dict['epoch'] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4785a9d0-9701-45bc-82a1-f7da3097eac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
