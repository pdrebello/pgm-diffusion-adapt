{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b7e8e-b0ff-4ab2-b6f6-c449c33a6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494bc73d-a94f-41ba-add7-ed4e2385991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d00b9d-2a2b-403c-852b-a71caa8e31a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVisionDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        root (string): Root directory of dataset where ``MNIST/raw/train-images-idx3-ubyte``\u001b[0m\n",
       "\u001b[0;34m            and  ``MNIST/raw/t10k-images-idx3-ubyte`` exist.\u001b[0m\n",
       "\u001b[0;34m        train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\u001b[0m\n",
       "\u001b[0;34m            otherwise from ``t10k-images-idx3-ubyte``.\u001b[0m\n",
       "\u001b[0;34m        download (bool, optional): If True, downloads the dataset from the internet and\u001b[0m\n",
       "\u001b[0;34m            puts it in root directory. If dataset is already downloaded, it is not\u001b[0m\n",
       "\u001b[0;34m            downloaded again.\u001b[0m\n",
       "\u001b[0;34m        transform (callable, optional): A function/transform that  takes in an PIL image\u001b[0m\n",
       "\u001b[0;34m            and returns a transformed version. E.g, ``transforms.RandomCrop``\u001b[0m\n",
       "\u001b[0;34m        target_transform (callable, optional): A function/transform that takes in the\u001b[0m\n",
       "\u001b[0;34m            target and transforms it.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmirrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"http://yann.lecun.com/exdb/mnist/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"https://ossci-datasets.s3.amazonaws.com/mnist/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0;34m\"train-images-idx3-ubyte.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f68b3c2dcbeaaa9fbdd348bbdeb94873\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0;34m\"train-labels-idx1-ubyte.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"d53e105ee54ea40749a09fcbcd1e9432\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0;34m\"t10k-images-idx3-ubyte.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"9fb629c4189551a2d022fa330f9573f3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0;34m\"t10k-labels-idx1-ubyte.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ec29112dd5afa0611ce80d1b7f02629c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtraining_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"training.pt\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test.pt\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"0 - zero\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"1 - one\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"2 - two\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"3 - three\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"4 - four\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"5 - five\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"6 - six\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"7 - seven\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"8 - eight\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"9 - nine\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_labels has been renamed targets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_labels has been renamed targets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_data has been renamed data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_data has been renamed data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m  \u001b[0;31m# training set or test set\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_legacy_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_legacy_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset not found. You can use download=True to download it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_check_legacy_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprocessed_folder_exists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprocessed_folder_exists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_load_legacy_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# This is for BC only. We no longer cache the data in a custom binary, but simply read from the raw data\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# directly.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_file\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{'train' if self.train else 't10k'}-images-idx3-ubyte\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlabel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{'train' if self.train else 't10k'}-labels-idx1-ubyte\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_label_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            index (int): Index\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            tuple: (image, target) where target is index of the target class.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mraw_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mprocessed_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"processed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0m_class\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Download the MNIST data if it doesn't exist already.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# download files\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mmirror\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmirrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{mirror}{filename}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading {url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to download (trying next):\\n{error}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error downloading {filename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Train\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"Split: {split}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/torch/lib/python3.11/site-packages/torchvision/datasets/mnist.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     FashionMNIST, KMNIST, EMNIST, QMNIST"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MNIST??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c43064-13d3-4232-8831-f4c48cfa01a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_folder = \"../data/weights/mnist\\,mnist_m\\,svhn\\,syn_digits_mnist/_num_domain\\:\\ 4_Twin_AC_AC_weight1.0_BigGAN_seed2019_Gch64_Dch64_bs200_nDs4_Glr2.0e-04_Dlr2.0e-04_Gnlrelu_Dnlrelu_GinitN02_DinitN02_Gshared_ema/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35f6d991-e272-4ae2-882d-795fbc90ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torchvision.datasets.vision import VisionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a4d428-f709-43fe-98a9-29913327ce4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740c2716-d6ce-4095-a201-ca4d92ec13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets.mnist import read_image_file\n",
    "\n",
    "    \n",
    "image_file = f\"/data/medical_images/ahn/DA_Infer/mnist_raw/MNIST/raw/train-images-idx3-ubyte\"\n",
    "data = read_image_file(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59319477-b53c-4ef2-897c-4fdd6b8f9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load(\"../data/svhn/SVHN_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be74c22f-bf54-4141-bcea-332495d57ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((73257, 32, 32, 3), (73257,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape, a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73fd5de8-4494-40d9-94fa-8b186829667f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b858828-ea20-499c-9d42-ad3221a96014",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# of this training run.\n",
    "\n",
    "\n",
    "  # Update the config dict as necessary\n",
    "  # This is for convenience, to add settings derived from the user-specified\n",
    "  # configuration into the config-dict (e.g. inferring the number of classes\n",
    "  # and size of the images from the dataset, passing in a pytorch object\n",
    "\n",
    "  # for the activation specified as a string)\n",
    "  config['resolution'] = 32#utils.imsize_dict[config['dataset']]\n",
    "  config['n_classes'] = 10#utils.nclass_dict[config['dataset']]\n",
    "  config['G_activation'] = utils.activation_dict[config['G_nl']]\n",
    "  config['D_activation'] = utils.activation_dict[config['D_nl']]\n",
    "  # By default, skip init if resuming training.\n",
    "  if config['resume']:\n",
    "    print('Skipping initialization for training resumption...')\n",
    "    config['skip_init'] = True\n",
    "  config = utils.update_config_roots(config)\n",
    "  device = 'cuda'\n",
    "  \n",
    "  # Seed RNG\n",
    "  utils.seed_rng(config['seed'])\n",
    "\n",
    "  # Prepare root folders if necessary\n",
    "  utils.prepare_root(config)\n",
    "\n",
    "  # Setup cudnn.benchmark for free speed\n",
    "  torch.backends.cudnn.benchmark = True\n",
    "\n",
    "  # Import the model--this line allows us to dynamically select different files.\n",
    "  model = __import__(config['model'])\n",
    "  experiment_name = (config['experiment_name'] if config['experiment_name']\n",
    "                       else utils.name_from_config(config))\n",
    "  run = wandb.init(\n",
    "        project=\"pgm_project\", \n",
    "        name=\"initial_run\",\n",
    "        job_type=\"Train\", \n",
    "        config=config,\n",
    "    )\n",
    "  print('Experiment name is %s' % experiment_name)\n",
    "\n",
    "  # Next, build the model\n",
    "  G = model.Generator(**config).to(device)\n",
    "  D = model.Discriminator(**config).to(device)\n",
    "\n",
    "   # If using EMA, prepare it\n",
    "  if config['ema']:\n",
    "    print('Preparing EMA for G with decay of {}'.format(config['ema_decay']))\n",
    "    G_ema = model.Generator(**{**config, 'skip_init':True,\n",
    "                               'no_optim': True}).to(device)\n",
    "    ema = utils.ema(G, G_ema, config['ema_decay'], config['ema_start'])\n",
    "  else:\n",
    "    ema = None\n",
    "  \n",
    "  # FP16?\n",
    "  if config['G_fp16']:\n",
    "    print('Casting G to float16...')\n",
    "    G = G.half()\n",
    "    if config['ema']:\n",
    "      G_ema = G_ema.half()\n",
    "  if config['D_fp16']:\n",
    "    print('Casting D to fp16...')\n",
    "    D = D.half()\n",
    "    # Consider automatically reducing SN_eps?\n",
    "  GD = model.G_D(G, D)\n",
    "  # print(G)\n",
    "  # print(D)\n",
    "  print('Number of params in G: {} D: {}'.format(\n",
    "    *[sum([p.data.nelement() for p in net.parameters()]) for net in [G,D]]))\n",
    "  # Prepare state dict, which holds things like epoch # and itr #\n",
    "  state_dict = {'itr': 0, 'epoch': 0, 'save_num': 0, 'save_best_num': 0,\n",
    "                'best_IS': 0, 'best_FID': 999999, 'config': config}\n",
    "\n",
    "  # If loading from a pre-trained model, load weights\n",
    "  if config['resume']:\n",
    "    print('Loading weights...')\n",
    "    utils.load_weights(G, D, state_dict,\n",
    "                       config['weights_root'], experiment_name, \n",
    "                       config['load_weights'] if config['load_weights'] else None,\n",
    "                       G_ema if config['ema'] else None)\n",
    "\n",
    "  # If parallel, parallelize the GD module\n",
    "  if config['parallel']:\n",
    "    GD = nn.DataParallel(GD)\n",
    "\n",
    "    if config['cross_replica']:\n",
    "      patch_replication_callback(GD)\n",
    "\n",
    "  # Prepare loggers for stats; metrics holds test metrics,\n",
    "  # lmetrics holds any desired training metrics.\n",
    "  test_metrics_fname = '%s/%s_log.jsonl' % (config['logs_root'],\n",
    "                                            experiment_name)\n",
    "  train_metrics_fname = '%s/%s' % (config['logs_root'], experiment_name)\n",
    "  print('Inception Metrics will be saved to {}'.format(test_metrics_fname))\n",
    "  test_log = utils.MetricsLogger(test_metrics_fname, \n",
    "                                 reinitialize=(not config['resume']))\n",
    "  print('Training Metrics will be saved to {}'.format(train_metrics_fname))\n",
    "  train_log = utils.MyLogger(train_metrics_fname, \n",
    "                             reinitialize=(not config['resume']),\n",
    "                             logstyle=config['logstyle'])\n",
    "  # Write metadata\n",
    "  utils.write_metadata(config['logs_root'], experiment_name, config, state_dict)\n",
    "  # Prepare data; the Discriminator's batch size is all that needs to be passed\n",
    "  # to the dataloader, as G doesn't require dataloading.\n",
    "  # Note that at every loader iteration we pass in enough data to complete\n",
    "  # a full D iteration (regardless of number of D steps and accumulations)\n",
    "  D_batch_size = (config['batch_size'] * config['num_D_steps']\n",
    "                  * config['num_D_accumulations'])\n",
    "\n",
    "  transforms_train = transforms.Compose([transforms.Resize(config['resolution']),transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "  print(config['base_root'])\n",
    "  data_set = source_domain_numpy(root=config['base_root'], root_list=config['source_dataset'], transform=transforms_train)\n",
    "  # loaders = utils.get_data_loaders(**{**config, 'batch_size': D_batch_size,\n",
    "  #                                     'start_itr': state_dict['itr']})\n",
    "  loaders = torch.utils.data.DataLoader(data_set, batch_size=D_batch_size, shuffle=True,\n",
    "           num_workers=config['num_workers'],\n",
    "           pin_memory=True,\n",
    "           worker_init_fn=np.random.seed,drop_last=True)\n",
    "\n",
    "  test_set_s = domain_test_numpy(root= config['base_root'],\n",
    "                               root_t=config['target_dataset'], transform=transforms_train)\n",
    "  test_loader_s = torch.utils.data.DataLoader(test_set_s, batch_size=D_batch_size, shuffle=False,\n",
    "                                            num_workers=config['num_workers'],\n",
    "                                            pin_memory=True,\n",
    "                                            worker_init_fn=np.random.seed, drop_last=True)\n",
    "\n",
    "  test_set_t = domain_test_numpy(root= config['base_root'],root_t=config['target_dataset'],transform=transforms_train)\n",
    "  test_loader_t = torch.utils.data.DataLoader(test_set_t, batch_size=D_batch_size, shuffle=False,\n",
    "           num_workers=config['num_workers'],\n",
    "           pin_memory=True,\n",
    "           worker_init_fn=np.random.seed,drop_last=True)\n",
    "\n",
    "  # Prepare noise and randomly sampled label arrays\n",
    "  # Allow for different batch sizes in G\n",
    "  G_batch_size = max(config['G_batch_size'], config['batch_size'])\n",
    "  z_, y_, yd_ = utils.prepare_z_y(G_batch_size, G.dim_z, config['n_classes'],config['n_domain'],\n",
    "                             device=device, fp16=config['G_fp16'])\n",
    "  # Prepare a fixed z & y to see individual sample evolution throghout training\n",
    "  fixed_z, fixed_y, fixed_yd = utils.prepare_z_y(G_batch_size, G.dim_z,\n",
    "                                       config['n_classes'],config['n_domain'], device=device,\n",
    "                                       fp16=config['G_fp16'])\n",
    "  fixed_z.sample_()\n",
    "  fixed_y.sample_()\n",
    "  fixed_yd.sample_()\n",
    "  # Loaders are loaded, prepare the training function\n",
    "  if config['which_train_fn'] == 'GAN':\n",
    "    train = train_fns.GAN_training_function(G, D, GD, z_, y_,yd_,\n",
    "                                            ema, state_dict, config)\n",
    "  # Else, assume debugging and use the dummy train fn\n",
    "  else:\n",
    "    train = train_fns.dummy_training_function()\n",
    "  # Prepare Sample function for use with inception metrics\n",
    "  # sample = functools.partial(utils.sample,\n",
    "  #                             G=(G_ema if config['ema'] and config['use_ema']\n",
    "  #                                else G),\n",
    "  #                             z_=z_, y_=y_, config=config)\n",
    "\n",
    "  print('Beginning training at epoch %d...' % state_dict['epoch'])\n",
    "  # Train for specified number of epochs, although we mostly track G iterations.\n",
    "  for epoch in range(state_dict['epoch'], config['num_epochs']):\n",
    "    if epoch%10 == 0:\n",
    "        test_acc(D, test_loader_s)\n",
    "        test_acc(D, test_loader_t)\n",
    "    # Which progressbar to use? TQDM or my own?\n",
    "    if config['pbar'] == 'mine':\n",
    "      pbar = utils.progress(loaders,displaytype='s1k' if config['use_multiepoch_sampler'] else 'eta')\n",
    "    else:\n",
    "      pbar = tqdm(loaders)\n",
    "    for i, (x_s, y, yd) in enumerate(pbar):\n",
    "      # Increment the iteration counter\n",
    "      state_dict['itr'] += 1\n",
    "      # Make sure G and D are in training mode, just in case they got set to eval\n",
    "      # For D, which typically doesn't have BN, this shouldn't matter much.\n",
    "      G.train()\n",
    "      D.train()\n",
    "      if config['ema']:\n",
    "        G_ema.train()\n",
    "      if config['D_fp16']:\n",
    "        x_s,x_t, y = x_s.to(device).half(), x_t.to(device).half(), y.to(device)\n",
    "      else:\n",
    "        x_s, y, yd = x_s.to(device), y.to(device),yd.to(device)\n",
    "      metrics = train(x_s, y, yd)\n",
    "      # train_log.log(itr=int(state_dict['itr']), **metrics)\n",
    "      \n",
    "      # Every sv_log_interval, log singular values\n",
    "      if (config['sv_log_interval'] > 0) and (not (state_dict['itr'] % config['sv_log_interval'])):\n",
    "        train_log.log(itr=int(state_dict['itr']), \n",
    "                      **{**utils.get_SVs(G, 'G'), **utils.get_SVs(D, 'D')})\n",
    "\n",
    "      # If using my progbar, print metrics.\n",
    "      if config['pbar'] == 'mine':\n",
    "          print(', '.join(['itr: %d' % state_dict['itr']] \n",
    "                           + ['%s : %+4.3f' % (key, metrics[key])\n",
    "                           for key in metrics]), end=' ')\n",
    "          wandb_metric = {key: metrics[key] if type(metrics[key]) == float else metrics[key].item() for key in metrics.keys()}\n",
    "          wandb.log(wandb_metric)\n",
    "\n",
    "      # Save weights and copies as configured at specified interval\n",
    "      if not (state_dict['itr'] % config['save_every']):\n",
    "        if config['G_eval_mode']:\n",
    "          print('Switchin G to eval mode...')\n",
    "          G.eval()\n",
    "          if config['ema']:\n",
    "            G_ema.eval()\n",
    "        train_fns.save_and_sample(G, D, G_ema, z_, y_,yd_, fixed_z, fixed_y,fixed_yd,\n",
    "                                  state_dict, config, experiment_name)\n",
    "\n",
    "      # Test every specified interval\n",
    "      if not (state_dict['itr'] % config['test_every']):\n",
    "        if config['G_eval_mode']:\n",
    "          print('Switchin G to eval mode...')\n",
    "          G.eval()\n",
    "        # train_fns.test(G, D, G_ema, z_, y_, state_dict, config, sample,\n",
    "        #                get_inception_metrics, experiment_name, test_log)\n",
    "    # Increment epoch counter at end of epoch\n",
    "    state_dict['epoch'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a368cbf-5751-4e61-a9f7-96dda12d163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  # parse command line and run\n",
    "  parser = utils.prepare_parser()\n",
    "  config = vars(parser.parse_args())\n",
    "  print(config)\n",
    "  run(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c72d9-1ab5-4dc2-b33a-55e376be9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import *\n",
    "\n",
    "lauch_cmd = \"--loss_type Twin_AC --AC \\\\\\n--AC_weight 1.0 \\\\\\n--G_shared \\\\\\n--n_domain 4 \\\\\\n--shuffle --batch_size 200 \\\\\\n--num_G_accumulations 1 --num_D_accumulations 1 --num_epochs 1000 \\\\\\n--num_D_steps 4 --num_G_steps 1 --G_lr 2e-4 --D_lr 2e-4 \\\\\\n--source_dataset mnist,mnist_m,svhn,syn_digits --target_dataset mnist --num_workers 16 \\\\\\n--G_ortho 0.0 \\\\\\n--G_attn 0 --D_attn 0 --G_ch 64 --D_ch 64 \\\\\\n--G_init N02 --D_init N02 \\\\\\n--test_every 8000 --save_every 1000 --num_best_copies 5 --num_save_copies 2 --seed 2019 \\\\\\n--ema  --use_ema --ema_start 10000 \\\\\\n\"\n",
    "lauch_cmd = lauch_cmd.replace(\"\\\\\\n\",\"\")\n",
    "\n",
    "\n",
    "parser = utils.prepare_parser()\n",
    "config = vars(parser.parse_args(lauch_cmd.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5498a70-7a08-45dc-964a-9c5471b7700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the config dict as necessary\n",
    "# This is for convenience, to add settings derived from the user-specified\n",
    "# configuration into the config-dict (e.g. inferring the number of classes\n",
    "# and size of the images from the dataset, passing in a pytorch object\n",
    "\n",
    "# for the activation specified as a string)\n",
    "config['resolution'] = 32#utils.imsize_dict[config['dataset']]\n",
    "config['n_classes'] = 10#utils.nclass_dict[config['dataset']]\n",
    "config['G_activation'] = utils.activation_dict[config['G_nl']]\n",
    "config['D_activation'] = utils.activation_dict[config['D_nl']]\n",
    "\n",
    "config = utils.update_config_roots(config)\n",
    "device = 'cuda:6'\n",
    "\n",
    "# Seed RNG\n",
    "utils.seed_rng(config['seed'])\n",
    "\n",
    "# Prepare root folders if necessary\n",
    "utils.prepare_root(config)\n",
    "\n",
    "# Setup cudnn.benchmark for free speed\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Import the model--this line allows us to dynamically select different files.\n",
    "model = __import__(config['model'])\n",
    "\n",
    "# Next, build the model\n",
    "G = model.Generator(**config).to(device)\n",
    "D = model.Discriminator(**config).to(device)\n",
    "\n",
    "utils.load_weights(G, D, state_dict,\n",
    "                   config['weights_root'], experiment_name, \n",
    "                   True,\n",
    "                   False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222596a9-7490-4b54-b7cf-1bea9a8e65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_checkpoint = \"../data/weights/mnist,mnist_m,svhn,syn_digits_mnist/_num_domain: 4_Twin_AC_AC_weight1.0_BigGAN_seed2019_Gch64_Dch64_bs200_nDs4_Glr2.0e-04_Dlr2.0e-04_Gnlrelu_Dnlrelu_GinitN02_DinitN02_Gshared_ema/G.pth\"\n",
    "\n",
    "G.load_state_dict(torch.load(g_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926ced2-fc5e-409a-98c0-ea9aaa030d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_batch_size = max(config['G_batch_size'], config['batch_size'])\n",
    "z_, y_, yd_ = utils.prepare_z_y(G_batch_size, G.dim_z, config['n_classes'],config['n_domain'],\n",
    "                             device=device, fp16=config['G_fp16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2e2ee-5400-4331-ad0e-2eed24351313",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_.sample_()\n",
    "y_.sample_()\n",
    "yd_.sample_()\n",
    "\n",
    "shared_y_ = G.shared(y_)\n",
    "shared_yd_ = G.shared_d(yd_)\n",
    "out = G(z_, shared_y_, shared_yd_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb6cbdd-76dc-4394-b877-1f26cf32790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "figure(figsize=(30, 10), dpi=80)\n",
    "\n",
    "plots = 5\n",
    "count=0\n",
    "start = 8\n",
    "for index in range(start, start+20):\n",
    "  \n",
    "    \n",
    "    plt.subplot(1, plots, count+1)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    #img = Image.open(df_g.iloc[index]['png_path'])\n",
    "    #plt.imshow(data_source[index])\n",
    "    img = out[index].cpu().detach().numpy()\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    img = (img - img.min())/(img.max() - img.min())\n",
    "    plt.imshow(img)\n",
    "    plt.title((y_[index].item(),yd_[index].item()), fontsize=30)\n",
    "    count+=1\n",
    "    if(count == 5):\n",
    "        count = 0\n",
    "        figure(figsize=(30, 10), dpi=80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c70428-6c0f-424f-af65-55697e450b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If using EMA, prepare it\n",
    "if config['ema']:\n",
    "print('Preparing EMA for G with decay of {}'.format(config['ema_decay']))\n",
    "G_ema = model.Generator(**{**config, 'skip_init':True,\n",
    "                           'no_optim': True}).to(device)\n",
    "ema = utils.ema(G, G_ema, config['ema_decay'], config['ema_start'])\n",
    "else:\n",
    "ema = None\n",
    "\n",
    "# FP16?\n",
    "if config['G_fp16']:\n",
    "print('Casting G to float16...')\n",
    "G = G.half()\n",
    "if config['ema']:\n",
    "  G_ema = G_ema.half()\n",
    "if config['D_fp16']:\n",
    "print('Casting D to fp16...')\n",
    "D = D.half()\n",
    "# Consider automatically reducing SN_eps?\n",
    "GD = model.G_D(G, D)\n",
    "# print(G)\n",
    "# print(D)\n",
    "print('Number of params in G: {} D: {}'.format(\n",
    "*[sum([p.data.nelement() for p in net.parameters()]) for net in [G,D]]))\n",
    "# Prepare state dict, which holds things like epoch # and itr #\n",
    "state_dict = {'itr': 0, 'epoch': 0, 'save_num': 0, 'save_best_num': 0,\n",
    "            'best_IS': 0, 'best_FID': 999999, 'config': config}\n",
    "\n",
    "# If loading from a pre-trained model, load weights\n",
    "if config['resume']:\n",
    "print('Loading weights...')\n",
    "utils.load_weights(G, D, state_dict,\n",
    "                   config['weights_root'], experiment_name, \n",
    "                   config['load_weights'] if config['load_weights'] else None,\n",
    "                   G_ema if config['ema'] else None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
